{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, Image\n",
    "%matplotlib inline\n",
    "from numpy import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract function to extract all the subfolder under root\n",
    "def extract(root):\n",
    "    \"\"\"\n",
    "    Argument: \n",
    "    root -- name or dir of a folder\n",
    "    Return:\n",
    "    data_folder -- subfolders of root\n",
    "    \"\"\"\n",
    "    data_folders = [(os.path.join(root, d),d) for d in sorted(os.listdir(root)) if not d.startswith('.')]\n",
    "    print data_folders\n",
    "    return data_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_split(filenames, train_size):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    filenames -- list of filenames\n",
    "    train_size  -- ratio of train dataset (e.g. 0.8)\n",
    "    Return:\n",
    "    train_filenames -- list of train filenames\n",
    "    test_filenames -- list of test filenames\n",
    "    \"\"\"\n",
    "    filenames = sorted(filenames)\n",
    "    random.seed(230)\n",
    "    random.shuffle(filenames)\n",
    "    split_1 = int(train_size * len(filenames))\n",
    "    train_filenames = filenames[:split_1]\n",
    "    test_filenames = filenames[split_1:]\n",
    "    return train_filenames, test_filenames\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load function to load imgs from folder (contains several subfolders) and output a dataset and a labels\n",
    "# import image\n",
    "\n",
    "\n",
    "def load(data_folders,max_num_images, image_height, image_width, pixel_depth=255):\n",
    "    \"\"\"\n",
    "    Argument: \n",
    "    data_folders -- folders of different classes. Currently is nw and not_nw\n",
    "    max_num_images -- max number of images can pad into dataset. \n",
    "    image_height -- height of image\n",
    "    image_width -- width of image\n",
    "    pixel_depth -- depth of image, usually 225.0\n",
    "    Return:\n",
    "    Dataset -- dataset contains all the images in the folder, dimesion is [num_images, image_height, image_weith]\n",
    "    labels -- labels of images, dimension in [num_images], data range in range(classes)\n",
    "    \"\"\"\n",
    "    #print data_folders\n",
    "    dataset = np.ndarray(  # create a ndarray with (max_num_images, n_H, n_W)\n",
    "        shape=(max_num_images, image_height, image_width), dtype=np.float32) \n",
    "    labels = np.ndarray(shape=(max_num_images), dtype=np.int32)\n",
    "    label_index = 0 # label index start from 0\n",
    "    image_index = 0 # image_index start from 0\n",
    "    for folder in data_folders:\n",
    "        #print folder\n",
    "        category_dict[folder[1]] = label_index\n",
    "        #print os.listdir(folder)\n",
    "        for image in os.listdir(folder[0]):\n",
    "            image_file = os.path.join(folder[0], image)\n",
    "            try:\n",
    "                image_data = (plt.imread(image_file).astype(float) -\n",
    "                              pixel_depth / 2) / pixel_depth # normalize image\n",
    "                if image_data.shape != (image_height, image_width):\n",
    "                    raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "                dataset[image_index, :, :] = image_data\n",
    "                labels[image_index] = label_index\n",
    "                image_index += 1 # read another image\n",
    "            except IOError as e:\n",
    "                print 'Could not read:', image_file, ':', e, '- it\\'s ok, skipping.'\n",
    "        label_index += 1 # next folder, next label\n",
    "    num_images = image_index\n",
    "    dataset = dataset[0:num_images, :, :]\n",
    "    labels = labels[0:num_images]\n",
    "    print 'Full dataset tensor:', dataset.shape\n",
    "    print 'Mean:', np.mean(dataset)\n",
    "    print 'Standard deviation:', np.std(dataset)\n",
    "    print 'Labels:', labels.shape\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split_folder(nw_folder_path, not_nw_folder_path, train_folders_path, test_folders_path, train_size):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    nw_folder_path -- path to the nw imgs folder\n",
    "    not_nw_folder_path -- path to the not_nw imgs folder\n",
    "    train_folder_path -- folder of train dataset, will contain 2 sub dataset\n",
    "    test_folder_path -- folder of test dataset, will contain 2 sub dataset\n",
    "    Return:\n",
    "    None -- just need to copy and split pictures in nw_folder, not_nw_folder and put them in train_folder and test_folder\n",
    "    \"\"\"\n",
    "    if not os.path.exists(train_folders_path) : # create train_folder if not exist, also create sub folder\n",
    "        os.makedirs(train_folders_path)\n",
    "        os.makedirs(train_folders_path + \"/nws\")\n",
    "        os.makedirs(train_folders_path + \"/not_nws\")\n",
    "    if not os.path.exists(test_folders_path): # create test_folder if not exist, also create sub folder\n",
    "        os.makedirs(test_folders_path)\n",
    "        os.makedirs(test_folders_path + \"/nws\")\n",
    "        os.makedirs(test_folders_path + \"/not_nws\")\n",
    "    nw_filenames = os.listdir(nw_folder_path) # list of all the nw imgs \n",
    "    not_nw_filenames = os.listdir(not_nw_folder_path) # list of all the non_nw imgs\n",
    "    \n",
    "    nw_train, nw_test = file_split(nw_filenames, train_size) # split nw imgs and output filenames\n",
    "    not_nw_train, not_nw_test = file_split(not_nw_filenames, train_size) # split not_nw imgs and output filenames\n",
    "    \n",
    "    imgs = (nw_train, nw_test, not_nw_train, not_nw_test)\n",
    "    folder_names = (nw_folder_path, nw_folder_path, not_nw_folder_path, not_nw_folder_path)\n",
    "    dest_names = (train_folder_path + \"nws\", test_folder_path + \"nws\",\n",
    "                  train_folder_path + \"not_nws\", test_folder_path + \"not_nws\")\n",
    "    print imgs\n",
    "    print folder_names\n",
    "    print dest_names\n",
    "\n",
    "    for file_names, folder, dest in zip(imgs, folder_names, dest_names ):\n",
    "        for file_name in file_names:\n",
    "            full_file_name = os.path.join(folder, file_name)\n",
    "            if (os.path.isfile(full_file_name)):\n",
    "                shutil.copy(full_file_name, dest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
